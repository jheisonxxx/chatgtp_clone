from fastapi import APIRouter, Depends, HTTPException, File, UploadFile, Form, Body
from fastapi.responses import JSONResponse
import openai
import pandas as pd
from pydantic import BaseModel
import os

from app.schemas.chatgtp import ApiKeyRequest

router = APIRouter(prefix="/chatgtp")

UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'csv'}
MAX_ROWS = 100  # Maximum row limit

@router.post("/verify_apikey")
def is_api_key_valid(api_key_request: ApiKeyRequest):
    openai.api_key = api_key_request.apikey
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "This is a test"}
            ]
        )
        if response['id'] is not None:
            return JSONResponse(content={
                "message": "Valid API token. You can use de API."
            }, status_code=200)
        else:
            return JSONResponse(content={
                "message": "API token invalid. Verify your token and the configuration.",
            }, status_code=401)

    except Exception as e:
        raise HTTPException(status_code=401, detail="Error to validate API token:" + str(e))


def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


def verify_csv(file: UploadFile):

    if not allowed_file(file.filename):
        raise HTTPException(status_code=400, detail="Tipo de archivo no permitido")

    if file.content_type != 'text/csv':
        raise HTTPException(status_code=400, detail="Tipo de archivo incorrecto")

    file_start_position = file.file.tell()
    file_size = file.file.tell() - file_start_position  # File size without loading into memory
    file.file.seek(file_start_position)

    if file_size > 1024 * 1024:  # 1MB
        raise HTTPException(status_code=400, detail="El archivo es demasiado grande")

    df = pd.read_csv(file.file)
    # Check number of columns
    if len(df.columns) > 10:  # Cambiar el número según tus necesidades
            raise HTTPException(status_code=400, detail="Cantidad incorrecta de columnas")

    # Limit the number of rows
    if len(df) > MAX_ROWS:
        raise HTTPException(status_code=400, detail=f"Se excede el límite máximo de filas ({MAX_ROWS})")

    return df

@router.post('/upload-file')
def upload_file(file: UploadFile = File(...), apikey: str = Form(...)):
    apikey_data = {
        "apikey": apikey,
    }
    apikey_request = ApiKeyRequest(**apikey_data)
    response = is_api_key_valid(apikey_request)
    if response.status_code == 200:
        try:
            df = verify_csv(file)
            # Parse columns and generate initial description using ChatGPT
            columns = ", ".join(df.columns)
            description_prompt = f"Este es un CSV con las siguientes columnas: {columns}. ¿Puedes proporcionar una descripción inicial de los datos y sugerir análisis?"
            openai.api_key = apikey
            chat_response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": description_prompt}
                ]
            )

            analysis_suggestions = chat_response.choices[0].message['content'] + "\n\n"

            description_prompt = f"Este es un CSV con las siguientes columnas: {columns}. ¿Puedes proporcionar el tipo de informacion de cada columna Por ejemplo numerica categorica?"

            chat_response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": description_prompt}
                ]
            )

            # Interpret the response generated by ChatGPT and present it to the user
            analysis_suggestions = analysis_suggestions + chat_response.choices[0].message['content'] + "\n\n"

            description_prompt = f"Este es un CSV con las siguientes columnas: {columns}. ¿Puedes proporcionar los patrones observables?"

            chat_response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": description_prompt}
                ]
            )

            # Interpret the response generated by ChatGPT and present it to the user
            analysis_suggestions = analysis_suggestions + chat_response.choices[0].message['content'] + "\n\n"

            return JSONResponse(content={
                "message": "CSV uploaded and initial analysis generated",
                "data_description": analysis_suggestions
            }, status_code=200)

        except pd.errors.EmptyDataError:
            return JSONResponse(content={"error": "Uploaded CSV is empty"}, status_code=400)
        except Exception as e:
            return JSONResponse(content={"error": "I can't give you an analysis now: " + str(e)}, status_code=500)

    else:
        return response

